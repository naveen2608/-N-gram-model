{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveen2608/-N-gram-model/blob/n-gram/Copy_of_complete_Ngram_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing the required libraries**"
      ],
      "metadata": {
        "id": "PBnsL4qDHKyQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCxqYn1IJa1u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import tarfile\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Connecting google drive with notebook**"
      ],
      "metadata": {
        "id": "D8JwMqqJHZZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ayzjOxfOjThV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Extracting data from the tar file which was downloaded from the https://devopedia.org/text-corpus-for-nlp.**"
      ],
      "metadata": {
        "id": "xdL4YXuiHm6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **To extract data from tarfile we've imported the module `tar`**"
      ],
      "metadata": {
        "id": "-1dmXmuDIRNU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUuWrQFEuYOP",
        "outputId": "344e4639-1293-49e7-d3ab-ced89212d1ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import tarfile\n",
        "fname = \"/content/drive/MyDrive/nlp dataset/aclImdb_v1.tar.gz\"\n",
        "tar = tarfile.open(fname, \"r:gz\")\n",
        "tar.extractall('.')\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creaintg corpus from downloaded data**"
      ],
      "metadata": {
        "id": "LBf-YIYmIxUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0izDg-rLA5F"
      },
      "outputs": [],
      "source": [
        "reviews = []\n",
        "def adder(file):\n",
        "  for i in os.listdir(file):\n",
        "    fname = os.path.join(file,i)\n",
        "    f = open(fname,'r')\n",
        "    reviews.append(f.read().split(\".\"))\n",
        "\n",
        "adder(\"/content/aclImdb/train/pos\")\n",
        "adder(\"/content/aclImdb/train/neg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jBO0SS3EVA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022524cd-9a42-4c1a-f860-b95bbc8ab324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "len(reviews) #total no of reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Size of the corpus**"
      ],
      "metadata": {
        "id": "SKkYeRyKJM1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRAmXHy4FIK_",
        "outputId": "fc5df407-c4b0-44fc-9eac-79bb005b9ebb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305571"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "data = []\n",
        "for i in reviews:\n",
        "  for j in i:\n",
        "    if j!=\"\":\n",
        "      data.append(j)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rplVow-A0EPU",
        "outputId": "f3151b9f-a4be-428d-c5fb-575e93a3cbd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' In solving one set of problems, Guiness has created dozens of others'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "data[60]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Removing punctuations and additional html tags from the corpus(i.e.,cleaning data)**"
      ],
      "metadata": {
        "id": "-Lf9BLmVJV_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaFAHLFIXNze"
      },
      "outputs": [],
      "source": [
        "reg = \"<br /><br />|\\'s|\\.\\.+|\\!|\\@|\\#|\\$|\\%|\\^|\\&|\\*|\\(|\\)|\\_|\\-|\\=|\\+|\\}|\\{|\\[|\\]|\\:|\\;|\\'|\\\"|\\>|\\<|\\,|\\/|\\`|\\~\"\n",
        "def tagremover(sent):\n",
        "  sent = re.sub(reg,\" \",sent)\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ2i-DjCYkry"
      },
      "outputs": [],
      "source": [
        "for i in range(len(data)):\n",
        "  data[i] = tagremover(data[i]).lower().strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "_FMBq33kifcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIjyqCXg0o0f"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Ngram model(i.e., finding ngram probabilities)**"
      ],
      "metadata": {
        "id": "_FO1qJ0kJkVL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ7tBk7h-nSk"
      },
      "outputs": [],
      "source": [
        "class N_gram:\n",
        "  def __init__(self,data,n):\n",
        "    self.data = data\n",
        "    self.n = n\n",
        "  def gramDiv(self):\n",
        "    list_of_ngrams=[]\n",
        "    gram_count = dict()\n",
        "    hist_count = dict()\n",
        "    sent_data=[]\n",
        "    if n==1:\n",
        "      for i in tqdm(range(len(self.data))):\n",
        "        sentence = data[i].split()\n",
        "        for j in range(len(sentence)):\n",
        "          current_word = sentence[j]\n",
        "          list_of_ngrams.append((current_word))\n",
        "          gram_count[(current_word)] = gram_count.get((current_word), 0)+1\n",
        "          hist_count[(current_word)] = hist_count.get(((current_word)),0)+1\n",
        "    else:\n",
        "      for i in tqdm(range(len(self.data))):\n",
        "        sent = \"<s> \"*(self.n-1)+self.data[i]+\" </s>\"\n",
        "        sent_data.append(sent)\n",
        "\n",
        "        sentence = sent.split()\n",
        "        given_n_word = sentence[:self.n-1]\n",
        "        for j in range(self.n-1,len(sentence)):\n",
        "          current_word = sentence[j]\n",
        "          list_of_ngrams.append((tuple(given_n_word), current_word))\n",
        "          gram_count[(tuple(given_n_word), current_word)] = gram_count.get((tuple(given_n_word), current_word), 0)+1\n",
        "          hist_count[tuple(given_n_word)] = hist_count.get(tuple(given_n_word),0)+1\n",
        "          given_n_word.pop(0)\n",
        "          given_n_word +=[current_word]\n",
        "    return gram_count,hist_count,list_of_ngrams,sent_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTo05JFgfTb1"
      },
      "outputs": [],
      "source": [
        "n=int(input(\"Enter n-value:\"))\n",
        "obj = N_gram(data,n)\n",
        "gram_n1_count,gram_n0_count,list_of_ngrams,sent_data= obj.gramDiv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count_in_corpus(sent_data):\n",
        "  word_count_corpus=dict()\n",
        "  for i in tqdm(range(len(sent_data))):\n",
        "    for j in sent_data[i].split():\n",
        "      word_count_corpus[j]=word_count_corpus.get(j,0)+1\n",
        "  return word_count_corpus"
      ],
      "metadata": {
        "id": "98KpOXrpIDMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_corpus= word_count_in_corpus(sent_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr9ANA8VJMBt",
        "outputId": "a9d006ef-2484-491f-fc5a-c98dffa83b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 305571/305571 [00:01<00:00, 163715.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_corpus"
      ],
      "metadata": {
        "id": "DQrOPsiiR2wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_count_corpus) #vocabulary size i.e., unique words in corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z31Hg5eWJVRs",
        "outputId": "e0ead84c-8eb6-4543-a982-bf207a8ac85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80052"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gram_n1_count"
      ],
      "metadata": {
        "id": "WQPfoulU150d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gram_n0_count"
      ],
      "metadata": {
        "id": "4OymUNgW1whF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ngrams"
      ],
      "metadata": {
        "id": "9Cip-yG-kf5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_data"
      ],
      "metadata": {
        "id": "M9qTlFRi6Pud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding probabilities**"
      ],
      "metadata": {
        "id": "Dss6riUOJ4xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prob(gram_n0_count,gram_n1_count,list_of_ngrams):\n",
        "  ngram_probs=dict()\n",
        "  for i in list_of_ngrams:\n",
        "    numerator=gram_n1_count.get(i)\n",
        "    denominator=gram_n0_count.get(i[0])\n",
        "    ngram_probs[i]=numerator/denominator\n",
        "  return ngram_probs"
      ],
      "metadata": {
        "id": "yOfStBQMNlKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_probs=calculate_prob(gram_n0_count,gram_n1_count,list_of_ngrams)"
      ],
      "metadata": {
        "id": "LN1xfN9p5S7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aTlC78KorS1N",
        "outputId": "52dde32f-6c73-466d-e326-79942ec21fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a super  unusual film from audiard  read my lips is a pulpy  lonely  hearts thriller'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_probs #probabilities of ngrams"
      ],
      "metadata": {
        "id": "7hxT8hMp5iR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data= []\n",
        "def adder(file):\n",
        "  for i in os.listdir(file):\n",
        "    fname = os.path.join(file,i)\n",
        "    f = open(fname,'r')\n",
        "    test_data.append(f.read().split(\".\"))\n",
        "adder(\"/content/aclImdb/test/neg\")"
      ],
      "metadata": {
        "id": "bvKSAugRYKve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing `secrets` module of python for generating random text sentence from testing data**"
      ],
      "metadata": {
        "id": "zFETsE27KFsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import secrets"
      ],
      "metadata": {
        "id": "A1fNyFxJdVVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence=secrets.choice(secrets.choice(test_data))"
      ],
      "metadata": {
        "id": "AbKSKByXdYLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "D0Bm8Sa5_vq5",
        "outputId": "0b450e9d-dfd6-44e7-aa73-ae5ae16b1334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<br /><br />Even if the acting was decent the dialog is terrible! \"Ginormus\" and \"dick skinners\" just doesn\\'t really cut it'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence=tagremover(test_sentence).lower().strip()"
      ],
      "metadata": {
        "id": "ICjoE4POdeWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZqkUBM1e_23S",
        "outputId": "e4a7dbca-ad8e-44fc-eef4-c2b1a8c0cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'even if the acting was decent the dialog is terrible   ginormus  and  dick skinners  just doesn t really cut it'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding probabilities for test sentence**"
      ],
      "metadata": {
        "id": "ngazq8WbKUOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_for_test_sent(test_sentence,n):\n",
        "  list_of_ngrams_of_sent=[]\n",
        "  sent = \"<s> \"*(n-1)+test_sentence+\" </s>\"\n",
        "  sentence_list = sent.split()\n",
        "  given_n_word = sentence_list[:n-1]\n",
        "  for j in range(n-1,len(sentence_list)):\n",
        "    current_word = sentence_list[j]\n",
        "    list_of_ngrams_of_sent.append((tuple(given_n_word), current_word))\n",
        "    given_n_word.pop(0)\n",
        "    given_n_word +=[current_word]\n",
        "  return list_of_ngrams_of_sent,sentence_list"
      ],
      "metadata": {
        "id": "X-QGnMdPi1IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ngrams_of_sent,sentence_list=prob_for_test_sent(test_sentence,n)"
      ],
      "metadata": {
        "id": "qJZQuZCAAtc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ngrams_of_sent"
      ],
      "metadata": {
        "id": "IcWoWk_QZ0cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list"
      ],
      "metadata": {
        "id": "h7f5v26nDcOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding vocabulary size**"
      ],
      "metadata": {
        "id": "FkJrmWaNKgZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_of_V(sentence_list,word_count_corpus):\n",
        "  v=0\n",
        "  for i in range(len(sentence_list)):\n",
        "    if sentence_list[i] in word_count_corpus:\n",
        "      v+=word_count_corpus.get(sentence_list[i])\n",
        "  return v"
      ],
      "metadata": {
        "id": "OmmKwTQ0FtTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v=calc_of_V(sentence_list,word_count_corpus)"
      ],
      "metadata": {
        "id": "r5S0-6-ZK11w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3hgN_lMK9Ul",
        "outputId": "51573255-8618-42c9-ad78-ce8e1774ad47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2725995"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ngrams_of_sent"
      ],
      "metadata": {
        "id": "bY7kAqH6Rso3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ngrams_of_sent[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GOUm5qP7Y2yB",
        "outputId": "322fb0da-fc44-4b5d-cd34-d3ca0010e654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'even'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding `perplexity` for the test sentence**"
      ],
      "metadata": {
        "id": "8BsAX2REKpdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity_of_test_sent(list_of_ngrams_of_sent,n,v):\n",
        "  sent_prob=1\n",
        "  for j in list_of_ngrams_of_sent:\n",
        "    given_n_word=j[0]\n",
        "    current_word=j[1]\n",
        "    if ((given_n_word, current_word)) in gram_n1_count.keys():\n",
        "      numerator1=gram_n1_count.get((tuple(given_n_word), current_word))+1\n",
        "    if ((given_n_word, current_word)) not in gram_n1_count.keys():\n",
        "      numerator1=0+1\n",
        "    if given_n_word in gram_n0_count.keys():\n",
        "      denominator1=gram_n0_count.get(tuple(given_n_word))+v\n",
        "    if given_n_word not in gram_n0_count.keys():\n",
        "      denominator1=0+v\n",
        "    probobality=numerator1/denominator1\n",
        "    sent_prob*=probobality\n",
        "\n",
        "  return sent_prob"
      ],
      "metadata": {
        "id": "ttb06v-W-7gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_prob=perplexity_of_test_sent(list_of_ngrams_of_sent,n,v)"
      ],
      "metadata": {
        "id": "WCGqaVI9pbVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "print(\"perplexity of the test sentence in with respect to corpus\")\n",
        "math.pow(sent_prob,(1/len(sentence_list))) # perplexity of test sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54HrifVSK36V",
        "outputId": "4b9f96d3-b2e0-4702-98d5-b9db9818bd26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity of the test sentence in with respect to corpus\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0394467634122447e-05"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}